{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d3defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# Define the file to exclude\n",
    "excluded_file = 'Sets.csv'\n",
    "\n",
    "# Define the directory where you want to save the filtered CSV files\n",
    "output_csv_directory = 'output_csv'  # Change this to the directory where you want to save the filtered CSV files\n",
    "\n",
    "# Create the output directory for CSV files if it doesn't exist\n",
    "os.makedirs(output_csv_directory, exist_ok=True)\n",
    "\n",
    "# Define the directory where you want to save the Excel file\n",
    "output_excel_directory = 'output_excel'  # Change this to the directory where you want to save the Excel file\n",
    "\n",
    "# Create the output directory for the Excel file if it doesn't exist\n",
    "os.makedirs(output_excel_directory, exist_ok=True)\n",
    "\n",
    "# Specify the Excel file path\n",
    "excel_file_path = 'GENeSYS-MOD_User_Input_Settings_v03_phe_06-09-2023.xlsx'  # Replace with the path to your Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d170de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of sheet names to read\n",
    "sheets_to_read = ['Region_selection', 'Technology_selection', 'Storage_selection', 'Fuel_selection', 'Mode_of_operation_selection', 'Emission_selection', 'Modal_type_selection', 'Sector_selection', 'Year_selection']\n",
    "\n",
    "# Initialize an empty dictionary to store DataFrames\n",
    "data_frames = {}\n",
    "filtered_df = {}\n",
    "unique_values = {}\n",
    "\n",
    "unique_values_concatenated = pd.DataFrame()\n",
    "column_list = []\n",
    "\n",
    "\n",
    "# Read sheets and store them in the dictionary\n",
    "for sheet_name in sheets_to_read:\n",
    "    data_frames = pd.read_excel(excel_file_path, engine='openpyxl', sheet_name=sheet_name)\n",
    "\n",
    "    filtered_df= data_frames[data_frames.iloc[:, 1] == 1]# Assuming the second column is indexed at 1 (0-based index)\n",
    "\n",
    "    column_list.append(filtered_df.columns[0]) # collect column header for each set sheet\n",
    "   \n",
    "    unique_values= pd.DataFrame(filtered_df.iloc[:, 0].unique())  # Assuming the first column is indexed at 0 (0-based index)\n",
    "    unique_values_parameter = pd.DataFrame(unique_values)\n",
    "    \n",
    "    unique_values_concatenated = pd.concat([unique_values_concatenated, unique_values], axis=1)\n",
    "    \n",
    "# Need to put header to the dataframe\n",
    "unique_values_concatenated.columns = column_list\n",
    "\n",
    "# Create a CSV file containing unique values\n",
    "unique_values_csv_file_path = os.path.join(output_csv_directory, 'Sets.csv')\n",
    "unique_values_concatenated.to_csv(unique_values_csv_file_path, index=False, decimal='.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff37fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "data_frames = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a45607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of subdirectories in the current directory\n",
    "subdirectories = [d for d in os.listdir() if os.path.isdir(d) and d.startswith(\"Par_\")]\n",
    "# Initialize the Excel writer\n",
    "output_excel_file_path = os.path.join(output_excel_directory, 'output.xlsx')\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='openpyxl') as writer:\n",
    "    unique_values_concatenated.to_excel(writer, sheet_name='Sets', index=False, header=True)\n",
    "    \n",
    "    # Process CSV files in each subdirectory\n",
    "    for subdirectory in subdirectories:\n",
    "        csv_files = [f for f in os.listdir(subdirectory) if f.endswith('.csv')]\n",
    "         \n",
    "        for csv_file in csv_files:\n",
    "            # Construct the full path to the CSV file\n",
    "            csv_file_path = os.path.join(subdirectory, csv_file)\n",
    "            \n",
    "            # Read the CSV file into a Pandas DataFrame\n",
    "            df = pd.read_csv(csv_file_path, delimiter=',')\n",
    "            \n",
    "            # Create a list of columns to keep\n",
    "            columns_to_keep = [col for col in df.columns if col in unique_values_concatenated.columns or col == 'Value']\n",
    "        \n",
    "            # Filter the DataFrame to keep only the selected columns\n",
    "            df = df[columns_to_keep]\n",
    "            \n",
    "            # Create an empty dictionary to store filtered DataFrames\n",
    "            filtered_df = df\n",
    "\n",
    "            \n",
    "            # Iterate over unique_values_concatenated DataFrame columns\n",
    "            for header in unique_values_concatenated.columns:\n",
    "                if header in df.columns:\n",
    "                    # Filter the DataFrame based on whether the values in the header column are present in unique_values_concatenated\n",
    "                    filtered_df = filtered_df[filtered_df[header].isin(unique_values_concatenated[header])]\n",
    "                else:\n",
    "                    # If the header column is not found, copy the entire DataFrame\n",
    "                    filtered_df = filtered_df.copy()\n",
    "                \n",
    "            filtered_df = pd.concat([filtered_df.columns.to_frame().T, filtered_df], ignore_index=True)\n",
    "            filtered_df.columns = range(len(df.columns))\n",
    "            \n",
    "            df_final = filtered_df\n",
    "            \n",
    "            df_final.replace('nan', '', inplace=True)\n",
    "            df_final.apply(lambda x: x.apply(lambda y: str(y).replace('.', ',')))\n",
    "            \n",
    "            # Get the worksheet name without the .csv extension\n",
    "            worksheet_name = os.path.splitext(csv_file)[0]\n",
    "            \n",
    "            # Store the DataFrame in the dictionary with the filename (without extension) as the key\n",
    "            data_frames[worksheet_name] = df_final\n",
    "            \n",
    "            # Construct the full path to the output CSV file\n",
    "            output_csv_file_path = os.path.join(output_csv_directory, csv_file)\n",
    "            \n",
    "            # Save the filtered DataFrame to the CSV file without the index\n",
    "            df_final.to_csv(output_csv_file_path, index=False, header=False, decimal='.')\n",
    "            \n",
    "            # Save the filtered DataFrame to the Excel file without the index\n",
    "            df_final.to_excel(writer, sheet_name=worksheet_name, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7d248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
