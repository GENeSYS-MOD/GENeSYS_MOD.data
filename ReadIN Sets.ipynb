{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d3defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import math\n",
    "\n",
    "# Define the file to exclude\n",
    "excluded_file = 'Sets.csv'\n",
    "\n",
    "# Define the directory where you want to save the filtered CSV files\n",
    "output_csv_directory = 'output_csv'  # Change this to the directory where you want to save the filtered CSV files\n",
    "\n",
    "# Create the output directory for CSV files if it doesn't exist\n",
    "os.makedirs(output_csv_directory, exist_ok=True)\n",
    "\n",
    "# Define the directory where you want to save the Excel file\n",
    "output_excel_directory = 'output_excel'  # Change this to the directory where you want to save the Excel file\n",
    "\n",
    "# Create the output directory for the Excel file if it doesn't exist\n",
    "os.makedirs(output_excel_directory, exist_ok=True)\n",
    "\n",
    "# Specify the Excel file path\n",
    "excel_file_path = 'GENeSYS-MOD_User_Input_Settings_v03_phe_06-09-2023.xlsx'  # Replace with the path to your Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d170de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Excel file\n",
    "xls = pd.ExcelFile(excel_file_path, engine='openpyxl')\n",
    "\n",
    "# Get the list of sheet names in the Excel file\n",
    "sheets_to_read = xls.sheet_names\n",
    "\n",
    "# Initialize an empty dictionary to store DataFrames\n",
    "data_frames = {}\n",
    "filtered_df = {}\n",
    "unique_values = {}\n",
    "\n",
    "unique_values_concatenated = pd.DataFrame()\n",
    "column_list = []\n",
    "\n",
    "# Read sheets and store them in the dictionary\n",
    "for sheet_name in sheets_to_read:\n",
    "    data_frames = xls.parse(sheet_name)\n",
    "\n",
    "    filtered_df= data_frames[data_frames.iloc[:, 1] == 1] # Assuming the second column is indexed at 1 (0-based index)\n",
    "\n",
    "    column_list.append(filtered_df.columns[0]) # collect column header for each set sheet\n",
    "   \n",
    "    unique_values= pd.DataFrame(filtered_df.iloc[:, 0].unique())  # Assuming the first column is indexed at 0 (0-based index)\n",
    "    unique_values_parameter = pd.DataFrame(unique_values)\n",
    "    \n",
    "    unique_values_concatenated = pd.concat([unique_values_concatenated, unique_values], axis=1)\n",
    "\n",
    "# Need to put header to the dataframe\n",
    "unique_values_concatenated.columns = column_list\n",
    "\n",
    "# Create a CSV file containing unique values\n",
    "unique_values_csv_file_path = os.path.join(output_csv_directory, 'Sets.csv')\n",
    "unique_values_concatenated.to_csv(unique_values_csv_file_path, index=False, decimal='.') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff37fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "data_frames = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a45607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories\n",
    "current_directory = os.getcwd()\n",
    "sets_and_tags_directory = os.path.join(current_directory, '00_Sets&Tags')\n",
    "\n",
    "# Get a list of subdirectories in the current directory\n",
    "subdirectories_current = [d for d in os.listdir(current_directory) if os.path.isdir(os.path.join(current_directory, d)) and d.startswith(\"Par_\")]\n",
    "\n",
    "# Get list of csv files starting with Par_ from 00_Sets&Tags\n",
    "par_csv_files_sets_and_tags = [f for f in os.listdir(sets_and_tags_directory) if f.startswith('Par_') and f.endswith('.csv')]\n",
    "\n",
    "# For those CSV files, we'll treat their path as a \"subdirectory\" (even though they aren't directories)\n",
    "par_csv_filepaths_sets_and_tags = [os.path.join(sets_and_tags_directory, f) for f in par_csv_files_sets_and_tags]\n",
    "\n",
    "# Combine subdirectories from the current directory with filepaths from 00_Sets&Tags\n",
    "all_paths = subdirectories_current + par_csv_filepaths_sets_and_tags\n",
    "\n",
    "\n",
    "# Initialize the Excel writer\n",
    "output_excel_file_path = os.path.join(output_excel_directory, 'output.xlsx')\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='openpyxl') as writer:\n",
    "    unique_values_concatenated.to_excel(writer, sheet_name='Sets', index=False, header=True)\n",
    "    \n",
    "    # Process CSV files in each path\n",
    "    for path in all_paths:\n",
    "        if os.path.isdir(path):\n",
    "            # If it's a directory, list all CSV files within\n",
    "            csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "            csv_filepaths = [os.path.join(path, f) for f in csv_files]\n",
    "        else:\n",
    "            # If it's a CSV file, use it directly\n",
    "            csv_filepaths = [path]\n",
    "            \n",
    "\n",
    "        for csv_file_path in csv_filepaths:\n",
    "            # Read the CSV file into a Pandas DataFrame\n",
    "            df = pd.read_csv(csv_file_path, delimiter=',')\n",
    "            \n",
    "            # Create a list of columns to keep\n",
    "            columns_to_keep = [col for col in df.columns if col in unique_values_concatenated.columns or col == 'Value']\n",
    "            \n",
    "            # Filter the DataFrame to keep only the selected columns\n",
    "            df = df[columns_to_keep]\n",
    "            \n",
    "            pivot_indices = [col for col in unique_values_concatenated.columns if col in df.columns]\n",
    "        \n",
    "            # Iterate over unique_values_concatenated DataFrame columns\n",
    "            for header in unique_values_concatenated.columns:\n",
    "                if header in df.columns:\n",
    "                    # Filter the DataFrame based on whether the values in the header column are present in unique_values_concatenated\n",
    "                    df = df[df[header].isin(unique_values_concatenated[header])]\n",
    "            \n",
    "            # Pivot after filtering\n",
    "            if 'Year' in df.columns:\n",
    "                cols_to_drop = [col for col in df.columns if col not in unique_values_concatenated.columns and col not in ['Year', 'Value']]\n",
    "                df = df.drop(columns=cols_to_drop)\n",
    "                df = df.pivot_table(index=pivot_indices, columns='Year', values='Value', aggfunc='first').reset_index()\n",
    "                if 'Year' in df.columns:\n",
    "                    df = df.drop(columns='Year')\n",
    "   \n",
    "            filtered_df = df    \n",
    "    \n",
    "            filtered_df = pd.concat([filtered_df.columns.to_frame().T, filtered_df], ignore_index=True)\n",
    "            filtered_df.columns = range(len(df.columns))\n",
    "        \n",
    "            df_final = filtered_df\n",
    "        \n",
    "            df_final.replace('nan', '', inplace=True)\n",
    "            df_final.apply(lambda x: x.apply(lambda y: str(y).replace('.', ',')))\n",
    "        \n",
    "            # Get the worksheet name without the .csv extension\n",
    "            worksheet_name = os.path.splitext(os.path.basename(csv_file_path))[0]\n",
    "        \n",
    "            # Store the DataFrame in the dictionary with the filename (without extension) as the key\n",
    "            data_frames[worksheet_name] = df_final\n",
    "        \n",
    "            # Construct the full path to the output CSV file\n",
    "            output_csv_file_path = os.path.join(output_csv_directory, os.path.basename(csv_file_path))\n",
    "        \n",
    "            # Save the filtered DataFrame to the CSV file without the index\n",
    "            df_final.to_csv(output_csv_file_path, index=False, header=False, decimal='.')\n",
    "        \n",
    "            # Save the filtered DataFrame to the Excel file without the index\n",
    "            df_final.to_excel(writer, sheet_name=worksheet_name, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c7d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of subdirectories in the current directory\n",
    "subdirectories_TS = [d for d in os.listdir() if os.path.isdir(d) and d.startswith(\"TS_\")]\n",
    "# Initialize the Excel writer for hourly (TS_) files     \n",
    "output_excel_file_path_TS = os.path.join(output_excel_directory, 'output_TS.xlsx')\n",
    "with pd.ExcelWriter(output_excel_file_path_TS, engine='openpyxl') as writer:\n",
    "    # Process CSV files in each subdirectory\n",
    "    for subdirectory in subdirectories_TS:\n",
    "        # Logic to read in the hourly files and exporting the data for GENeSYS-MOD as .csv or excel file\n",
    "        csv_files = [f for f in os.listdir(subdirectory) if f.endswith('.csv')]\n",
    "         \n",
    "        for csv_file in csv_files:# Construct the full path to the CSV file\n",
    "            csv_file_path = os.path.join(subdirectory, csv_file)\n",
    "            \n",
    "            df_TS = pd.read_csv(csv_file_path, delimiter=',', skiprows=[0])\n",
    "            \n",
    "            # Create a DataFrame containing only the \"hour\" column\n",
    "            hour_column = df_TS[\"HOUR\"].to_frame()\n",
    "\n",
    "            #Create a list called \"selected_regions\" containing the unique values from the \"Region\" column\n",
    "            selected_regions_TS = unique_values_concatenated[\"Region\"].unique().tolist()\n",
    "\n",
    "            selected_regions_TS = [value for value in selected_regions_TS if not isinstance(value, float) or not math.isnan(value)]\n",
    "\n",
    "            #Filter the columns in the \"TS_WIND_ONSHORE_INF.csv\" DataFrame\n",
    "            filtered_df_TS = df_TS[selected_regions_TS]\n",
    "\n",
    "            # Concatenate the \"hour\" DataFrame as the first row of the filtered DataFrame\n",
    "            filtered_df_TS = pd.concat([hour_column, filtered_df_TS], axis=1, ignore_index=False)\n",
    "            \n",
    "            df_TS_final = filtered_df_TS\n",
    "            \n",
    "            # Get the worksheet name without the .csv extension\n",
    "            worksheet_name = os.path.splitext(csv_file)[0]\n",
    "            \n",
    "            # Store the DataFrame in the dictionary with the filename (without extension) as the key\n",
    "            data_frames[worksheet_name] = df_TS_final\n",
    "            \n",
    "            \n",
    "            # Write the DataFrame to an Excel worksheet with the same filename (without extension)\n",
    "            df_TS_final.to_excel(writer, sheet_name=worksheet_name, index=False, header=True)\n",
    "            \n",
    "            \n",
    "            # Specify the path where you want to save the CSV file\n",
    "            output_csv_file_path = os.path.join(output_csv_directory, csv_file)\n",
    "\n",
    "            # Use the to_csv method to save the DataFrame to a CSV file\n",
    "            df_TS_final.to_csv(output_csv_file_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5772f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
