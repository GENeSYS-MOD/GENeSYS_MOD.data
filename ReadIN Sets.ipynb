{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d3defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# Define the directory where your CSV files are located\n",
    "csv_directory = 'csvs'  # Change this to the directory containing your CSV files\n",
    "\n",
    "# Define the file to exclude\n",
    "excluded_file = 'Sets.csv'\n",
    "\n",
    "# Define the directory where you want to save the filtered CSV files\n",
    "output_csv_directory = 'output_csv'  # Change this to the directory where you want to save the filtered CSV files\n",
    "\n",
    "# Create the output directory for CSV files if it doesn't exist\n",
    "os.makedirs(output_csv_directory, exist_ok=True)\n",
    "\n",
    "# Define the directory where you want to save the Excel file\n",
    "output_excel_directory = 'output_excel'  # Change this to the directory where you want to save the Excel file\n",
    "\n",
    "# Create the output directory for the Excel file if it doesn't exist\n",
    "os.makedirs(output_excel_directory, exist_ok=True)\n",
    "\n",
    "# Specify the Excel file path\n",
    "excel_file_path = 'GENeSYS-MOD_User_Input_Settings_v03_phe_06-09-2023.xlsx'  # Replace with the path to your Excel file\n",
    "\n",
    "\n",
    "# Create a list of unique values in the fourth column of the filtered DataFrame\n",
    "#unique_values_region = filtered_df_region.iloc[:, 3].unique()  # Assuming the fourth column is indexed at 3 (0-based index)\n",
    "#unique_values_technology = filtered_df_technology.iloc[:, 0].unique()  # Assuming the first column is indexed at 0 (0-based index)\n",
    "#unique_values_storage = filtered_df_storage.iloc[:, 0].unique()  # Assuming the first column is indexed at 0 (0-based index)\n",
    "#unique_values_year = filtered_df_year.iloc[:, 0].unique()  # Assuming the first column is indexed at 0 (0-based index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d170de21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Storage</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Mode_of_operation</th>\n",
       "      <th>Emission</th>\n",
       "      <th>Modal_type</th>\n",
       "      <th>Sectors</th>\n",
       "      <th>Selected Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE-BY-UF</td>\n",
       "      <td>A_Air</td>\n",
       "      <td>S_PHS</td>\n",
       "      <td>Area_Rooftop_Commercial</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CO2</td>\n",
       "      <td>MT_PSNG_ROAD</td>\n",
       "      <td>Power</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO1</td>\n",
       "      <td>A_Rooftop_Residential</td>\n",
       "      <td>S_Battery_Li-Ion</td>\n",
       "      <td>Biomass</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MT_PSNG_AIR</td>\n",
       "      <td>Buildings</td>\n",
       "      <td>2025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE-BY</td>\n",
       "      <td>D_Battery_Li-Ion</td>\n",
       "      <td>S_Battery_Redox</td>\n",
       "      <td>Hardcoal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MT_PSNG_ROAD_RE</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>2030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN-Cen</td>\n",
       "      <td>D_Battery_Redox</td>\n",
       "      <td>S_Heat_HLR</td>\n",
       "      <td>H2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MT_PSNG_RAIL_RE</td>\n",
       "      <td>Resources</td>\n",
       "      <td>2040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN-Cen-Henan</td>\n",
       "      <td>D_CAES</td>\n",
       "      <td>S_Heat_HLI</td>\n",
       "      <td>Gas_Natural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MT_PSNG_AIR_RE</td>\n",
       "      <td>Storages</td>\n",
       "      <td>2045.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Region             Technology           Storage  \\\n",
       "0      DE-BY-UF                  A_Air             S_PHS   \n",
       "1           NO1  A_Rooftop_Residential  S_Battery_Li-Ion   \n",
       "2         DE-BY       D_Battery_Li-Ion   S_Battery_Redox   \n",
       "3        CN-Cen        D_Battery_Redox        S_Heat_HLR   \n",
       "4  CN-Cen-Henan                 D_CAES        S_Heat_HLI   \n",
       "\n",
       "                      Fuel  Mode_of_operation Emission       Modal_type  \\\n",
       "0  Area_Rooftop_Commercial                1.0      CO2     MT_PSNG_ROAD   \n",
       "1                  Biomass                3.0      NaN      MT_PSNG_AIR   \n",
       "2                 Hardcoal                4.0      NaN  MT_PSNG_ROAD_RE   \n",
       "3                       H2                NaN      NaN  MT_PSNG_RAIL_RE   \n",
       "4              Gas_Natural                NaN      NaN   MT_PSNG_AIR_RE   \n",
       "\n",
       "          Sectors  Selected Years  \n",
       "0           Power          2020.0  \n",
       "1       Buildings          2025.0  \n",
       "2  Transportation          2030.0  \n",
       "3       Resources          2040.0  \n",
       "4        Storages          2045.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of sheet names to read\n",
    "sheets_to_read = ['Region_selection', 'Technology_selection', 'Storage_selection', 'Fuel_selection', 'Mode_of_operation_selection', 'Emission_selection', 'Modal_type_selection', 'Sector_selection', 'Year_selection']\n",
    "\n",
    "# Initialize an empty dictionary to store DataFrames\n",
    "data_frames = {}\n",
    "filtered_df = {}\n",
    "unique_values = {}\n",
    "\n",
    "unique_values_concatenated = pd.DataFrame()\n",
    "column_list = []\n",
    "\n",
    "\n",
    "# Read sheets and store them in the dictionary\n",
    "for sheet_name in sheets_to_read:\n",
    "    data_frames = pd.read_excel(excel_file_path, engine='openpyxl', sheet_name=sheet_name)\n",
    "\n",
    "    filtered_df= data_frames[data_frames.iloc[:, 1] == 1]# Assuming the second column is indexed at 1 (0-based index)\n",
    "\n",
    "    column_list.append(filtered_df.columns[0]) # collect column header for each set sheet\n",
    "   \n",
    "    unique_values= pd.DataFrame(filtered_df.iloc[:, 0].unique())  # Assuming the first column is indexed at 0 (0-based index)\n",
    "    unique_values_parameter = pd.DataFrame(unique_values)\n",
    "    \n",
    "    unique_values_concatenated = pd.concat([unique_values_concatenated, unique_values], axis=1)\n",
    "    \n",
    "# Need to put header to the dataframe\n",
    "unique_values_concatenated.columns = column_list\n",
    "\n",
    "# Create a CSV file containing unique values\n",
    "unique_values_csv_file_path = os.path.join(output_csv_directory, 'Sets.csv')\n",
    "unique_values_concatenated.to_csv(unique_values_csv_file_path, index=False, decimal='.') \n",
    "unique_values_concatenated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff37fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "data_frames = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a45607b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 33\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m filtered_df[filtered_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[43munique_values_concatenated\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39mcopy()    \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "# Initialize the Excel writer\n",
    "output_excel_file_path = os.path.join(output_excel_directory, 'output.xlsx')\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='openpyxl') as writer:\n",
    "    unique_values_concatenated.to_excel(writer, sheet_name='Sets', index=False, header=True)\n",
    "    for filename in os.listdir(csv_directory):\n",
    "        if filename.endswith('.csv') and filename != excluded_file:\n",
    "            # Construct the full path to the CSV file\n",
    "            csv_file_path = os.path.join(csv_directory, filename)\n",
    "            \n",
    "            df_first = pd.read_csv(csv_file_path, delimiter=';',header=None)\n",
    "            df_header = df_first.iloc[:4] #shweta\n",
    "            df_header = df_header.apply(lambda x: x.apply(lambda y: str(y).replace('.0', '')))\n",
    "            df_header = df_header.iloc[:4, :1]\n",
    "            \n",
    "            # Read the CSV file into a Pandas DataFrame, skipping the first 4 rows\n",
    "            df = pd.read_csv(csv_file_path, delimiter=';', skiprows=4)\n",
    "            \n",
    "            if \"Region\" in df.columns:\n",
    "                # Filter the DataFrame based on whether the values in the \"Region\" column are present in unique_values\n",
    "                filtered_df = df[df[\"Region\"].isin(unique_values_concatenated[\"Region\"])]\n",
    "                if \"Region2\" in df.columns:\n",
    "                    filtered_df = filtered_df[filtered_df[\"Region2\"].isin(unique_values_concatenated[\"Region\"])]  \n",
    "            else:\n",
    "                # If \"Region\" column is not found, copy the entire DataFrame\n",
    "                filtered_df = df.copy()\n",
    "                \n",
    "            if \"Technology\" in df.columns:\n",
    "                filtered_df = filtered_df[filtered_df[\"Technology\"].isin(unique_values_concatenated[\"Technology\"])]\n",
    "            else:\n",
    "                filtered_df = filtered_df.copy()\n",
    "                \n",
    "            if \"Year\" in df.columns:\n",
    "                filtered_df = filtered_df[filtered_df[\"Year\"].isin(unique_values_concatenated[\"Year\"])]\n",
    "            else:\n",
    "                filtered_df = filtered_df.copy()    \n",
    "                \n",
    "            filtered_df = pd.concat([filtered_df.columns.to_frame().T, filtered_df], ignore_index=True)\n",
    "            filtered_df.columns = range(len(df.columns))\n",
    "            \n",
    "            df_final = pd.concat([df_header, filtered_df], axis=0)\n",
    "            \n",
    "            df_final.replace('nan', '', inplace=True)\n",
    "            df_final.apply(lambda x: x.apply(lambda y: str(y).replace('.', ',')))\n",
    "            \n",
    "            # Get the worksheet name without the .csv extension\n",
    "            worksheet_name = os.path.splitext(filename)[0]\n",
    "            \n",
    "            # Store the DataFrame in the dictionary with the filename (without extension) as the key\n",
    "            data_frames[worksheet_name] = df_final\n",
    "            \n",
    "            # Write the DataFrame to an Excel worksheet with the same filename (without extension)\n",
    "            df_final.to_excel(writer, sheet_name=worksheet_name, index=False, header=False)\n",
    "            \n",
    "            # Construct the full path to the output CSV file\n",
    "            output_csv_file_path = os.path.join(output_csv_directory, filename)\n",
    "            \n",
    "            # Save the filtered DataFrame to the CSV file without the index\n",
    "            df_final.to_csv(output_csv_file_path, index=False, header=False, decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c30d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
