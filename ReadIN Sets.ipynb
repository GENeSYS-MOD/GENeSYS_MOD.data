{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d3defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# Define the directory where your CSV files are located\n",
    "csv_directory = 'csvs'  # Change this to the directory containing your CSV files\n",
    "\n",
    "# Define the file to exclude\n",
    "excluded_file = 'Sets.csv'\n",
    "\n",
    "# Define the directory where you want to save the filtered CSV files\n",
    "output_csv_directory = 'output_csv'  # Change this to the directory where you want to save the filtered CSV files\n",
    "\n",
    "# Create the output directory for CSV files if it doesn't exist\n",
    "os.makedirs(output_csv_directory, exist_ok=True)\n",
    "\n",
    "# Define the directory where you want to save the Excel file\n",
    "output_excel_directory = 'output_excel'  # Change this to the directory where you want to save the Excel file\n",
    "\n",
    "# Create the output directory for the Excel file if it doesn't exist\n",
    "os.makedirs(output_excel_directory, exist_ok=True)\n",
    "\n",
    "# Specify the Excel file path\n",
    "excel_file_path = 'GENeSYS-MOD_User_Input_Settings_v03_phe_06-09-2023.xlsx'  # Replace with the path to your Excel file\n",
    "\n",
    "\n",
    "# Create a list of unique values in the fourth column of the filtered DataFrame\n",
    "#unique_values_region = filtered_df_region.iloc[:, 3].unique()  # Assuming the fourth column is indexed at 3 (0-based index)\n",
    "#unique_values_technology = filtered_df_technology.iloc[:, 0].unique()  # Assuming the first column is indexed at 0 (0-based index)\n",
    "#unique_values_storage = filtered_df_storage.iloc[:, 0].unique()  # Assuming the first column is indexed at 0 (0-based index)\n",
    "#unique_values_year = filtered_df_year.iloc[:, 0].unique()  # Assuming the first column is indexed at 0 (0-based index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d170de21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     filtered_df\u001b[38;5;241m=\u001b[39m data_frames[data_frames\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;66;03m# Assuming the second column is indexed at 1 (0-based index)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     unique_values\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(filtered_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munique())  \u001b[38;5;66;03m# Assuming the first column is indexed at 0 (0-based index)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     unique_values_parameter \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_values\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     unique_values_concatenated \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([unique_values_concatenated, unique_values], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Create a CSV file containing unique values\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:656\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m have_series:\n\u001b[0;32m    659\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "# Create a list of sheet names to read\n",
    "sheets_to_read = ['Region_selection', 'Technology_selection', 'Storage_selection', 'Fuel_selection', 'Mode_of_operation_selection', 'Emission_selection', 'Modal_type_selection', 'Sector_selection', 'Year_selection']\n",
    "\n",
    "# Initialize an empty dictionary to store DataFrames\n",
    "data_frames = {}\n",
    "filtered_df = {}\n",
    "unique_values = {}\n",
    "\n",
    "unique_values_concatenated = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Read sheets and store them in the dictionary\n",
    "for sheet_name in sheets_to_read:\n",
    "    data_frames = pd.read_excel(excel_file_path, engine='openpyxl', sheet_name=sheet_name)\n",
    "\n",
    "    filtered_df= data_frames[data_frames.iloc[:, 1] == 1]# Assuming the second column is indexed at 1 (0-based index)\n",
    "\n",
    "    unique_values= pd.DataFrame(filtered_df.iloc[:, 0].unique())  # Assuming the first column is indexed at 0 (0-based index)\n",
    "    unique_values_parameter = pd.DataFrame({sheet_name: unique_values})\n",
    "    \n",
    "    unique_values_concatenated = pd.concat([unique_values_concatenated, unique_values], axis=1)\n",
    "    \n",
    "# Create a CSV file containing unique values\n",
    "unique_values_csv_file_path = os.path.join(output_csv_directory, 'Sets.csv')\n",
    "unique_values_concatenated.to_csv(unique_values_csv_file_path, index=False, decimal='.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e897bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for unique values\n",
    "unique_values_region_df = pd.DataFrame({'Region': unique_values_region})\n",
    "unique_values_technology_df = pd.DataFrame({'Technology': unique_values_technology})\n",
    "unique_values_storage_df = pd.DataFrame({'Storage': unique_values_storage})\n",
    "unique_values_year_df = pd.DataFrame({'Year': unique_values_year})\n",
    "\n",
    "# Concatenate the DataFrames vertically\n",
    "unique_values_concatenated = pd.concat([unique_values_region_df, unique_values_technology_df, unique_values_year_df, unique_values_storage_df], axis=1)\n",
    "\n",
    "# Create a CSV file containing unique values\n",
    "unique_values_csv_file_path = os.path.join(output_csv_directory, 'Sets.csv')\n",
    "unique_values_concatenated.to_csv(unique_values_csv_file_path, index=False, decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff37fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store DataFrames\n",
    "data_frames = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Excel writer\n",
    "output_excel_file_path = os.path.join(output_excel_directory, 'output.xlsx')\n",
    "with pd.ExcelWriter(output_excel_file_path, engine='openpyxl') as writer:\n",
    "    unique_values_concatenated.to_excel(writer, sheet_name='Sets', index=False, header=True)\n",
    "    for filename in os.listdir(csv_directory):\n",
    "        if filename.endswith('.csv') and filename != excluded_file:\n",
    "            # Construct the full path to the CSV file\n",
    "            csv_file_path = os.path.join(csv_directory, filename)\n",
    "            \n",
    "            df_first = pd.read_csv(csv_file_path, delimiter=';',header=None)\n",
    "            df_header = df_first.iloc[:4] #shweta\n",
    "            df_header = df_header.apply(lambda x: x.apply(lambda y: str(y).replace('.0', '')))\n",
    "            df_header = df_header.iloc[:4, :1]\n",
    "            \n",
    "            # Read the CSV file into a Pandas DataFrame, skipping the first 4 rows\n",
    "            df = pd.read_csv(csv_file_path, delimiter=';', skiprows=4)\n",
    "            \n",
    "            if \"Region\" in df.columns:\n",
    "                # Filter the DataFrame based on whether the values in the \"Region\" column are present in unique_values\n",
    "                filtered_df = df[df[\"Region\"].isin(unique_values_region)]\n",
    "                if \"Region2\" in df.columns:\n",
    "                    filtered_df = filtered_df[filtered_df[\"Region2\"].isin(unique_values_region)]  \n",
    "            else:\n",
    "                # If \"Region\" column is not found, copy the entire DataFrame\n",
    "                filtered_df = df.copy()\n",
    "                \n",
    "            if \"Technology\" in df.columns:\n",
    "                filtered_df = filtered_df[filtered_df[\"Technology\"].isin(unique_values_technology)]\n",
    "            else:\n",
    "                filtered_df = filtered_df.copy()\n",
    "                \n",
    "            if \"Year\" in df.columns:\n",
    "                filtered_df = filtered_df[filtered_df[\"Year\"].isin(unique_values_year)]\n",
    "            else:\n",
    "                filtered_df = filtered_df.copy()    \n",
    "                \n",
    "            filtered_df = pd.concat([filtered_df.columns.to_frame().T, filtered_df], ignore_index=True)\n",
    "            filtered_df.columns = range(len(df.columns))\n",
    "            \n",
    "            df_final = pd.concat([df_header, filtered_df], axis=0)\n",
    "            \n",
    "            df_final.replace('nan', '', inplace=True)\n",
    "            df_final.apply(lambda x: x.apply(lambda y: str(y).replace('.', ',')))\n",
    "            \n",
    "            # Get the worksheet name without the .csv extension\n",
    "            worksheet_name = os.path.splitext(filename)[0]\n",
    "            \n",
    "            # Store the DataFrame in the dictionary with the filename (without extension) as the key\n",
    "            data_frames[worksheet_name] = df_final\n",
    "            \n",
    "            # Write the DataFrame to an Excel worksheet with the same filename (without extension)\n",
    "            df_final.to_excel(writer, sheet_name=worksheet_name, index=False, header=False)\n",
    "            \n",
    "            # Construct the full path to the output CSV file\n",
    "            output_csv_file_path = os.path.join(output_csv_directory, filename)\n",
    "            \n",
    "            # Save the filtered DataFrame to the CSV file without the index\n",
    "            df_final.to_csv(output_csv_file_path, index=False, header=False, decimal='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
