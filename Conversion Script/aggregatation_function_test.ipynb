{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration from the YAML file\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csvs(main_folder):\n",
    "    for root, dirs, files in os.walk(main_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                # Yield the DataFrame and the file path (optional, for reference)\n",
    "                yield df, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(df, method, index_count):\n",
    "    group_by_columns = df.columns[:index_count].tolist()\n",
    "    \n",
    "    \n",
    "    if method == 'sum':\n",
    "        \n",
    "        # Automatically detect numeric and non-numeric columns\n",
    "        aggregation_functions = {}\n",
    "        for col in df.columns:\n",
    "            if col in group_by_columns:\n",
    "                continue  \n",
    "\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                aggregation_functions[col] = 'sum'  \n",
    "            else:\n",
    "                aggregation_functions[col] = 'first'  # Keep the first value for non-numeric columns\n",
    "\n",
    "        # Apply the aggregation dynamically\n",
    "        df = df.groupby(group_by_columns).agg(aggregation_functions).reset_index()\n",
    "        return df\n",
    "    \n",
    "    elif method == 'average':\n",
    "        return df.groupby(group_by_columns).mean().reset_index()\n",
    "    \n",
    "    elif method == 'copy':\n",
    "        return df.copy()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Aggregation method '{method}' is not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(config, main_folder, output_path):\n",
    "    no_change_files = config.get('no_change_parameters', [])\n",
    "    \n",
    "    for df, file_path in load_csvs(main_folder):\n",
    "        print(df.columns)\n",
    "        param_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        print('Extracted param_name:', param_name)\n",
    "\n",
    "        if param_name in no_change_files:\n",
    "            print(f\"Skipping {param_name} as it is in the no_change_parameters list.\")\n",
    "            continue\n",
    "        \n",
    "        # Apply the changes based on the config\n",
    "        param_config = config.get(param_name, None)\n",
    "\n",
    "        if not param_config:\n",
    "            print(f\"No configuration found for {param_name}.\")  \n",
    "            continue\n",
    "       \n",
    "        agg_method = param_config.get('aggregation_Method')\n",
    "        index_count = param_config.get('index_count')\n",
    "        \n",
    "        # Fetch region-specific configuration for this parameter from regions.yaml\n",
    "        region_config = config.get('regions', None)\n",
    "        new_region = config.get('new_regions')\n",
    "        print(new_region)\n",
    "        \n",
    "        if region_config:\n",
    "            # Get regions to aggregate and new region\n",
    "            regions_to_aggregate = region_config\n",
    "            \n",
    "\n",
    "            # Check if regions are defined properly\n",
    "            if not regions_to_aggregate or not new_region:\n",
    "                print(f\"Invalid region configuration for {param_name}. Skipping.\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"No region configuration found for {param_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Filter the data to include only rows with regions to aggregate\n",
    "        if 'Region' in df.columns:  \n",
    "            df_to_aggregate = df[df['Region'].isin(regions_to_aggregate)]\n",
    "        else:\n",
    "            print(f\"No 'Region' column found in {param_name}. Skipping.\")\n",
    "            continue\n",
    "                \n",
    "        # Apply aggregation based on config\n",
    "        aggregated_df = aggregate_data(df_to_aggregate, agg_method, index_count) # not creating new region. need to take a look in aggregate_data function\n",
    "        print(aggregated_df.tail())\n",
    "        aggregated_df.to_csv('agg_test.csv')\n",
    "\n",
    "        #require fixing \n",
    "        aggregated_df['Region'] = new_region  \n",
    "        df = pd.concat([df, aggregated_df], ignore_index=True)\n",
    "        \n",
    "        # Save the updated DataFrame to a new location\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Updated {param_name} with aggregated data for new region {output_path}.\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Region', 'Technology', 'Year', 'Value', 'Unnamed: 4', 'Unit', 'Source',\n",
      "       'Updated at', 'Updated by'],\n",
      "      dtype='object')\n",
      "Extracted param_name: Par_TotalAnnualMaxCapacity\n",
      "['SCANDENAVIA']\n",
      "    Region            Technology  Year      Value  Unnamed: 4 Unit  Source  \\\n",
      "491     SE  RES_Wind_Onshore_Opt  2030  40.473333         0.0   GW     0.0   \n",
      "492     SE  RES_Wind_Onshore_Opt  2035  40.473333         0.0   GW     0.0   \n",
      "493     SE  RES_Wind_Onshore_Opt  2040  40.473333         0.0   GW     0.0   \n",
      "494     SE  RES_Wind_Onshore_Opt  2045  40.473333         0.0   GW     0.0   \n",
      "495     SE  RES_Wind_Onshore_Opt  2050  40.473333         0.0   GW     0.0   \n",
      "\n",
      "     Updated at  Updated by  \n",
      "491         0.0         0.0  \n",
      "492         0.0         0.0  \n",
      "493         0.0         0.0  \n",
      "494         0.0         0.0  \n",
      "495         0.0         0.0  \n"
     ]
    }
   ],
   "source": [
    "config = load_config('config.yaml')\n",
    "#regions_config = load_config('regions.yaml')\n",
    "\n",
    "main_folder = '../Parameters' \n",
    "output_path = '../Parameters' \n",
    "   \n",
    "process_files(config, main_folder, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/shwetat/Projects/Genesys-mod_data_repo/GENeSYS_MOD.data/Data/Parameters/Par_TotalAnnualMaxActivity/Par_TotalAnnualMaxActivity.csv\n",
      "  Region   Technology  Year       Value  Unnamed: 4 Unit  \\\n",
      "0     AT  RES_Biomass  2018  152.797266         NaN   PJ   \n",
      "1     BE  RES_Biomass  2018   93.198168         NaN   PJ   \n",
      "2     BG  RES_Biomass  2018  102.325392         NaN   PJ   \n",
      "3     CH  RES_Biomass  2018  152.797266         NaN   PJ   \n",
      "4     CZ  RES_Biomass  2018  144.381798         NaN   PJ   \n",
      "\n",
      "                                              Source  Updated at  \\\n",
      "0  Biomass Future Atlas of Technical and Economic...  07.09.2023   \n",
      "1  Biomass Future Atlas of Technical and Economic...  07.09.2023   \n",
      "2  Biomass Future Atlas of Technical and Economic...  07.09.2023   \n",
      "3  Biomass Future Atlas of Technical and Economic...  07.09.2023   \n",
      "4  Biomass Future Atlas of Technical and Economic...  07.09.2023   \n",
      "\n",
      "                              Updated by  \n",
      "0  Jonathan Hanto <joh@wip.tu-berlin.de>  \n",
      "1  Jonathan Hanto <joh@wip.tu-berlin.de>  \n",
      "2  Jonathan Hanto <joh@wip.tu-berlin.de>  \n",
      "3  Jonathan Hanto <joh@wip.tu-berlin.de>  \n",
      "4  Jonathan Hanto <joh@wip.tu-berlin.de>  \n"
     ]
    }
   ],
   "source": [
    "main_folder = \"/Users/shwetat/Projects/Genesys-mod_data_repo/GENeSYS_MOD.data/Data/Parameters\"\n",
    "\n",
    "# Iterate through each CSV file's DataFrame one by one\n",
    "for df, file_path in load_csvs(main_folder):\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    print(df.head())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "havnett",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
