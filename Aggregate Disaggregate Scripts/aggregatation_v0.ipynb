{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration from the YAML file\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csvs(main_folder):\n",
    "    for root, dirs, files in os.walk(main_folder):\n",
    "        print(root)\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                yield df, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process unchanged files\n",
    "def process_files(base_dir):\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                yield df, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_unchanged_files(config, main_folder, output_path):\n",
    "    # Process unchanged files\n",
    "    unchanged_files = config['no_change_parameters'] \n",
    "    for df, file_path in process_files(main_folder):\n",
    "        param_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        if param_name in unchanged_files:\n",
    "            #print(f\"Skipping {param_name} as it is in the no_change_parameters list.\")\n",
    "            file_path = os.path.join(output_path, f'{param_name}.csv')\n",
    "            df.to_csv(file_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def aggregate_data(df, method, index_count, regions_to_combine, new_region, output_csv=\"aggregated_data.csv\"):\n",
    "    \"\"\"\n",
    "    Aggregates data in a DataFrame based on the given regions and saves the result as a new CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        method (str): Aggregation method (e.g., 'sum', 'mean').\n",
    "        index_count (int): The number of index levels to use for aggregation.\n",
    "        regions_to_combine (list): List of region names to combine.\n",
    "        new_region (str): Name for the new aggregated region.\n",
    "        output_csv (str): Path to save the resulting CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The aggregated DataFrame.\n",
    "    \"\"\"\n",
    "    if method not in ['sum', 'mean']:\n",
    "        raise ValueError(\"Supported methods are 'sum' and 'mean'\")\n",
    "\n",
    "    df = df.reset_index()\n",
    "    index_columns = df.columns[:index_count].tolist()\n",
    "    df.set_index(index_columns, inplace=True)\n",
    "\n",
    "    # Filter rows corresponding to the regions to combine\n",
    "    filtered_df = df[df.index.get_level_values('Region').isin(regions_to_combine)]\n",
    "\n",
    "    aggregated_rows = []\n",
    "    grouped_by = index_columns[1:] \n",
    "    print(grouped_by)\n",
    "\n",
    "    for group in filtered_df.groupby(grouped_by):\n",
    "        group_data = group[1]\n",
    "        \n",
    "        if method == 'sum':\n",
    "            aggregated_row = group_data.sum(numeric_only=True)\n",
    "        elif method == 'mean':\n",
    "            aggregated_row = group_data.mean(numeric_only=True)\n",
    "        elif method == 'copy':\n",
    "            aggregated_row = group_data.copy()\n",
    "\n",
    "        aggregated_row['Region'] = new_region\n",
    "        \n",
    "        if isinstance(group[0], tuple):\n",
    "            for i, level_name in enumerate(grouped_by):\n",
    "                aggregated_row[level_name] = group[0][i]\n",
    "        else:\n",
    "            aggregated_row[grouped_by[0]] = group[0]\n",
    "\n",
    "        aggregated_rows.append(aggregated_row)\n",
    "\n",
    "    aggregated_df = pd.DataFrame(aggregated_rows)\n",
    "    result_df = df.copy() #[~df.index.get_level_values('Region').isin(regions_to_combine)]\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = pd.concat([result_df, aggregated_df], ignore_index=True)\n",
    "   \n",
    "    return result_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_changed_files(config, main_folder, output_path):\n",
    "    changed_files = config['changed_files']\n",
    "    \n",
    "    for df, file_path in process_files(main_folder):\n",
    "        param_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        file_path = os.path.join(output_path, f'{param_name}.csv')\n",
    "        for file in changed_files:\n",
    "            if param_name == file['file_name']:\n",
    "                method = file['method']\n",
    "                index_count = file['index_count']\n",
    "                regions_to_combine = file['regions_to_combine']\n",
    "                new_regions = file['new_regions']\n",
    "                print(param_name, method, index_count, new_regions, regions_to_combine)\n",
    "                df.set_index(df.columns[:index_count].tolist(), inplace=True)\n",
    "                aggregated_df = aggregate_data(df, method, index_count, regions_to_combine, new_regions) \n",
    "                aggregated_df.to_csv(file_path, index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "base_dir = \"/Users/shwetat/Projects/Genesys-mod_data_repo/GENeSYS_MOD.data/Data/Parameters\"\n",
    "output_dir = \"/Users/shwetat/Projects/Genesys-mod_data_repo/GENeSYS_MOD.data/DataNew\"\n",
    "config = load_config(\"config.yaml\")\n",
    "process_unchanged_files(config, base_dir, output_dir)\n",
    "aggregate_changed_files(config, base_dir, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "havnett",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
