{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration from the YAML file\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read csv files sequentially from the directory as dataframe\n",
    "def process_files(base_dir):\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                yield df, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_unchanged_files(config, main_folder, output_path):\n",
    "    # Process unchanged files\n",
    "    unchanged_files = config['parameters']['unchanged_files'] #list of files\n",
    "    # Load each CSV file from the main folder\n",
    "    for df, file_path in process_files(main_folder):\n",
    "        param_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        if param_name in unchanged_files:\n",
    "            #print(f\"Skipping {param_name} as it is in the no_change_parameters list.\")\n",
    "            file_path = os.path.join(output_path, f'{param_name}.csv')\n",
    "            df.to_csv(file_path)\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_changed_files(config, main_folder, output_path):\n",
    "    changed_files = config['parameters']['changed_files'] # list of file with parameters\n",
    "    \n",
    "    #Load each CSV file from the main folder\n",
    "    for df, file_path in process_files(main_folder):\n",
    "        #combined_new_regions = pd.DataFrame()\n",
    "        param_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(output_path, f'{param_name}.csv')\n",
    "        for file in changed_files:\n",
    "            if param_name == file['file_name']:\n",
    "                method = file['method']\n",
    "                index_count = file['index_count']\n",
    "                regions_to_split = file['regions_to_split']\n",
    "                new_regions = file['new_regions']\n",
    "                split_ratio = file['split_ratio']\n",
    "                print(param_name, method, index_count, regions_to_split, new_regions, split_ratio)\n",
    "                \n",
    "                df.set_index(df.columns[:index_count].tolist(), inplace=True)\n",
    "                \n",
    "                # Process regions to split\n",
    "                for region in regions_to_split:\n",
    "                    if region in df.index.get_level_values('Region'):\n",
    "                        print(\"True\")\n",
    "                        # Filter rows for the region to split\n",
    "                        region_data = df.loc[region]\n",
    "                        # Create new DataFrame for the split regions\n",
    "                        \n",
    "                        new_region_dfs = []\n",
    "                        for new_region, ratio in split_ratio.items():\n",
    "                            if index_count == 1:\n",
    "                                new_data = region_data.to_frame().T if isinstance(region_data, pd.Series) else region_data.copy()\n",
    "                                new_data['Value'] *= ratio\n",
    "                                new_data['Region'] = new_region\n",
    "                                new_data.reset_index(inplace=True, drop=True)\n",
    "                                new_region_dfs.append(new_data)\n",
    "                            else:\n",
    "                                new_data = region_data.copy()\n",
    "                                new_data['Value'] *= ratio\n",
    "                                new_data['Region'] = new_region\n",
    "                                new_data.reset_index(inplace=True) \n",
    "                                new_region_dfs.append(new_data) \n",
    "                        combined_new_regions = pd.concat(new_region_dfs, ignore_index=True)\n",
    "                        # Add the new regions back to the original DataFrame\n",
    "                        df.reset_index(inplace=True)  # Temporarily reset the index\n",
    "                        df = pd.concat([df, combined_new_regions], ignore_index=True)\n",
    "\n",
    "                        # Reapply multi-index  \n",
    "                        df.set_index(df.columns[:index_count].tolist(), inplace=True)\n",
    "\n",
    "                        # Save the DataFrame to the constructed path\n",
    "                        df.to_csv(file_path)   \n",
    "\n",
    "                    else:\n",
    "                        print(\"do not have region in dataset\")\n",
    "                        df.to_csv(file_path)    \n",
    "\n",
    "                        combined_new_regions = pd.concat(new_region_dfs, ignore_index=True)  \n",
    "                        df.to_csv(file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_changed_files(config, main_folder, output_path):\n",
    "    trade_changed_files = config['parameters']['trade_files']  # Update from 'changed_files' to 'trade_files'\n",
    "    \n",
    "    # Load each CSV file from the main folder\n",
    "    for df, file_path in process_files(main_folder):\n",
    "        param_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        file_path = os.path.join(output_path, f'{param_name}.csv') \n",
    "        \n",
    "        for file in trade_changed_files:\n",
    "            if param_name == file['file_name']:\n",
    "                method = file['method']\n",
    "                index_count = file['index_count']\n",
    "                regions_to_split = file['regions_to_split']\n",
    "                new_regions = file['new_regions']\n",
    "                split_ratio = file['split_ratio']\n",
    "                new_connections = file.get('new_connections', {})  # Extract new connections\n",
    "                \n",
    "                print(param_name, method, index_count, regions_to_split, new_regions, split_ratio, new_connections)\n",
    "                \n",
    "                df.set_index(df.columns[:index_count].tolist(), inplace=True)\n",
    "\n",
    "                # Process regions to split\n",
    "                for region in regions_to_split:\n",
    "                    if region in df.index.get_level_values('Region'):\n",
    "                        print(f\"Processing region: {region}\")\n",
    "                        ref_row = df.loc[region].iloc[0].to_dict()  # Get only one reference row as dictionary\n",
    "                        \n",
    "                        # Filter rows where Region == 'NO'\n",
    "                        region_data = df.loc[region].copy() #added later\n",
    "                        index_cols = df.index.names #added later\n",
    "                        new_region_dfs = []\n",
    "                        \n",
    "                        # Standard region split\n",
    "                        for new_region, ratio in split_ratio.items():\n",
    "                            new_data = region_data.to_frame().T if isinstance(region_data, pd.Series) else region_data.copy()\n",
    "                            new_data['Value'] *= ratio\n",
    "                            \n",
    "                            # Modify 'Region' in place without adding a new column\n",
    "                            new_data.loc[:, \"Region\"] = new_region\n",
    "                            \n",
    "                            print(f\"new data:\", new_data.tail())\n",
    "                                                        \n",
    "                            new_data.reset_index(inplace=True)\n",
    "                            \n",
    "                            new_region_dfs.append(new_data)\n",
    "                        \n",
    "                        # Add new connections dynamically\n",
    "                        for key, details in new_connections.items():\n",
    "                            if \"-\" in key:\n",
    "                                reg1, reg2 = key.split(\"-\")\n",
    "\n",
    "                                # Manually create a new row for this connection\n",
    "                                conn_row = ref_row.copy()\n",
    "\n",
    "                                conn_row[index_cols[0]] = reg1  # Update first index column (e.g., 'Region')\n",
    "                                if len(index_cols) > 1:\n",
    "                                    conn_row[index_cols[1]] = reg2  # Update second index column (e.g., 'Region2')\n",
    "\n",
    "                                conn_row[\"Value\"] = details[\"value\"]  # Assign new connection value\n",
    "\n",
    "                                # Convert to DataFrame and add to list\n",
    "                                new_region_dfs.append(pd.DataFrame([conn_row]))\n",
    "                                print(f\"Added connection: {reg1} -> {reg2} with Value: {details['value']}\")\n",
    "\n",
    "\n",
    "                        combined_new_regions = pd.concat(new_region_dfs, ignore_index=True)\n",
    "                        \n",
    "                        # Add the new regions back to the original DataFrame\n",
    "                        df.reset_index(inplace=True)\n",
    "                        df = pd.concat([df, combined_new_regions], ignore_index=True)\n",
    "\n",
    "                        # Reapply multi-index\n",
    "                        df.set_index(df.columns[:index_count].tolist(), inplace=True)\n",
    "\n",
    "                        # Save the modified DataFrame\n",
    "                        df.to_csv(file_path)\n",
    "\n",
    "                    else:\n",
    "                        print(f\"Region {region} not found in dataset\")\n",
    "                        df.to_csv(file_path)\n",
    "\n",
    "    print(\"Processing completed.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par_GrowthRateTradeCapacity copy 2 ['NO'] ['NO1', 'NO2'] {'NO1': 1.0, 'NO2': 1.0} {'NO1-NO2': {'value': 23}, 'NO2-NO1': {'value': 45}}\n",
      "Processing region: NO\n",
      "new data:                Fuel  Year  Value  Unnamed: 5    Unit  \\\n",
      "Region2                                                \n",
      "UA            Power  2018    0.1         NaN  Factor   \n",
      "RU            Power  2018    0.1         NaN  Factor   \n",
      "BY            Power  2018    0.1         NaN  Factor   \n",
      "NONEU_Balkan  Power  2018    0.1         NaN  Factor   \n",
      "TR            Power  2018    0.1         NaN  Factor   \n",
      "\n",
      "                                    Source  Updated at  \\\n",
      "Region2                                                  \n",
      "UA            assumption (moved from code)  19.01.2024   \n",
      "RU            assumption (moved from code)  19.01.2024   \n",
      "BY            assumption (moved from code)  19.01.2024   \n",
      "NONEU_Balkan  assumption (moved from code)  19.01.2024   \n",
      "TR            assumption (moved from code)  19.01.2024   \n",
      "\n",
      "                                            Updated by Region  \n",
      "Region2                                                        \n",
      "UA            Nikita Moskalenko <nim@wip.tu-berlin.de>    NO1  \n",
      "RU            Nikita Moskalenko <nim@wip.tu-berlin.de>    NO1  \n",
      "BY            Nikita Moskalenko <nim@wip.tu-berlin.de>    NO1  \n",
      "NONEU_Balkan  Nikita Moskalenko <nim@wip.tu-berlin.de>    NO1  \n",
      "TR            Nikita Moskalenko <nim@wip.tu-berlin.de>    NO1  \n",
      "new data:                Fuel  Year  Value  Unnamed: 5    Unit  \\\n",
      "Region2                                                \n",
      "UA            Power  2018    0.1         NaN  Factor   \n",
      "RU            Power  2018    0.1         NaN  Factor   \n",
      "BY            Power  2018    0.1         NaN  Factor   \n",
      "NONEU_Balkan  Power  2018    0.1         NaN  Factor   \n",
      "TR            Power  2018    0.1         NaN  Factor   \n",
      "\n",
      "                                    Source  Updated at  \\\n",
      "Region2                                                  \n",
      "UA            assumption (moved from code)  19.01.2024   \n",
      "RU            assumption (moved from code)  19.01.2024   \n",
      "BY            assumption (moved from code)  19.01.2024   \n",
      "NONEU_Balkan  assumption (moved from code)  19.01.2024   \n",
      "TR            assumption (moved from code)  19.01.2024   \n",
      "\n",
      "                                            Updated by Region  \n",
      "Region2                                                        \n",
      "UA            Nikita Moskalenko <nim@wip.tu-berlin.de>    NO2  \n",
      "RU            Nikita Moskalenko <nim@wip.tu-berlin.de>    NO2  \n",
      "BY            Nikita Moskalenko <nim@wip.tu-berlin.de>    NO2  \n",
      "NONEU_Balkan  Nikita Moskalenko <nim@wip.tu-berlin.de>    NO2  \n",
      "TR            Nikita Moskalenko <nim@wip.tu-berlin.de>    NO2  \n",
      "Added connection: NO1 -> NO2 with Value: 23\n",
      "Added connection: NO2 -> NO1 with Value: 45\n",
      "Par_TradeCapacity copy 2 ['NO'] ['NO1', 'NO2'] {'NO1': 1.0, 'NO2': 1.0} {'NO1-NO2': {'value': 23}, 'NO2-NO1': {'value': 45}}\n",
      "Processing region: NO\n",
      "new data:            Fuel  Year  Value  Unnamed: 5 Unit                Source  \\\n",
      "Region.1                                                              \n",
      "NL        Power  2018  0.723         NaN   GW                   NaN   \n",
      "DE        Power  2018  1.444         NaN   GW                   NaN   \n",
      "DK        Power  2018  1.700         NaN   GW                   NaN   \n",
      "UK        Power  2018  2.800         NaN   GW                   NaN   \n",
      "SE        Power  2018  3.445         NaN   PJ  SciGRID_gas_IGGIELGN   \n",
      "\n",
      "          Updated at                             Updated by Region  \n",
      "Region.1                                                            \n",
      "NL               NaN                                    NaN    NO1  \n",
      "DE               NaN                                    NaN    NO1  \n",
      "DK               NaN                                    NaN    NO1  \n",
      "UK               NaN                                    NaN    NO1  \n",
      "SE        20.09.2023  Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "new data:            Fuel  Year  Value  Unnamed: 5 Unit                Source  \\\n",
      "Region.1                                                              \n",
      "NL        Power  2018  0.723         NaN   GW                   NaN   \n",
      "DE        Power  2018  1.444         NaN   GW                   NaN   \n",
      "DK        Power  2018  1.700         NaN   GW                   NaN   \n",
      "UK        Power  2018  2.800         NaN   GW                   NaN   \n",
      "SE        Power  2018  3.445         NaN   PJ  SciGRID_gas_IGGIELGN   \n",
      "\n",
      "          Updated at                             Updated by Region  \n",
      "Region.1                                                            \n",
      "NL               NaN                                    NaN    NO2  \n",
      "DE               NaN                                    NaN    NO2  \n",
      "DK               NaN                                    NaN    NO2  \n",
      "UK               NaN                                    NaN    NO2  \n",
      "SE        20.09.2023  Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "Added connection: NO1 -> NO2 with Value: 23\n",
      "Added connection: NO2 -> NO1 with Value: 45\n",
      "Par_TradeCapacityGrowthCosts copy 2 ['NO'] ['NO1', 'NO2'] {'NO1': 1.0, 'NO2': 1.0} {'NO1-NO2': {'value': 23}, 'NO2-NO1': {'value': 45}}\n",
      "Processing region: NO\n",
      "new data:                Fuel  Value  Unnamed: 4   Unit        Source  Updated at  \\\n",
      "Region.1                                                                  \n",
      "UA            Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "RU            Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "BY            Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "NONEU_Balkan  Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "TR            Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "\n",
      "                                         Updated by Region  \n",
      "Region.1                                                    \n",
      "UA            Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "RU            Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "BY            Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "NONEU_Balkan  Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "TR            Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "new data:                Fuel  Value  Unnamed: 4   Unit        Source  Updated at  \\\n",
      "Region.1                                                                  \n",
      "UA            Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "RU            Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "BY            Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "NONEU_Balkan  Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "TR            Power   5.51         NaN  M€/GW  needs update  20.09.2023   \n",
      "\n",
      "                                         Updated by Region  \n",
      "Region.1                                                    \n",
      "UA            Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "RU            Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "BY            Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "NONEU_Balkan  Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "TR            Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "Added connection: NO1 -> NO2 with Value: 23\n",
      "Added connection: NO2 -> NO1 with Value: 45\n",
      "Par_TradeRoute copy 2 ['NO'] ['NO1', 'NO2'] {'NO1': 1.0, 'NO2': 1.0} {'NO1-NO2': {'value': 23}, 'NO2-NO1': {'value': 45}}\n",
      "Processing region: NO\n",
      "new data:          Fuel  Value  Unnamed: 4 Unit  \\\n",
      "Region.1                                \n",
      "SE        ETS    1.0         NaN   km   \n",
      "SI        ETS    1.0         NaN   km   \n",
      "SK        ETS    1.0         NaN   km   \n",
      "UK        ETS    1.0         NaN   km   \n",
      "TR        ETS    1.0         NaN   km   \n",
      "\n",
      "                                                     Source  Updated at  \\\n",
      "Region.1                                                                  \n",
      "SE        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "SI        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "SK        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "UK        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "TR        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "\n",
      "                                     Updated by Region  \n",
      "Region.1                                                \n",
      "SE        Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "SI        Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "SK        Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "UK        Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "TR        Jonathan Hanto <joh@wip.tu-berlin.de>    NO1  \n",
      "new data:          Fuel  Value  Unnamed: 4 Unit  \\\n",
      "Region.1                                \n",
      "SE        ETS    1.0         NaN   km   \n",
      "SI        ETS    1.0         NaN   km   \n",
      "SK        ETS    1.0         NaN   km   \n",
      "UK        ETS    1.0         NaN   km   \n",
      "TR        ETS    1.0         NaN   km   \n",
      "\n",
      "                                                     Source  Updated at  \\\n",
      "Region.1                                                                  \n",
      "SE        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "SI        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "SK        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "UK        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "TR        Own calulation of distance - see txt.file for ...  05.09.2023   \n",
      "\n",
      "                                     Updated by Region  \n",
      "Region.1                                                \n",
      "SE        Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "SI        Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "SK        Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "UK        Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "TR        Jonathan Hanto <joh@wip.tu-berlin.de>    NO2  \n",
      "Added connection: NO1 -> NO2 with Value: 23\n",
      "Added connection: NO2 -> NO1 with Value: 45\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "base_dir = \"/Users/shwetat/Projects/Genesys-mod_data_repo/GENeSYS_MOD.data/Data/Parameters\"\n",
    "output_dir = \"/Users/shwetat/Projects/Genesys-mod_data_repo/GENeSYS_MOD.data/DataNew\"\n",
    "config = load_config(\"config_disaggregation.yaml\")\n",
    "#process_unchanged_files(config, base_dir, output_dir)\n",
    "#process_changed_files(config, base_dir, output_dir)\n",
    "trade_changed_files(config, base_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \"\"\" #Combine the new region DataFrames\n",
    "                combined_new_regions = pd.concat(new_region_dfs, ignore_index=True)\n",
    "\n",
    "                # Add the new regions back to the original DataFrame\n",
    "                df.reset_index(inplace=True)  # Temporarily reset the index\n",
    "                df = pd.concat([df, combined_new_regions], ignore_index=True)\n",
    "\n",
    "                # Reapply multi-index  \n",
    "                df.set_index(df.columns[:index_count].tolist(), inplace=True)\n",
    "\n",
    "                # Construct the full file path\n",
    "                file_path = os.path.join(output_path, f'{param_name}.csv')\n",
    "\n",
    "                # Save the DataFrame to the constructed path\n",
    "                df.to_csv(file_path) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to update DataFrame with new regions\n",
    "def add_new_regions(df, region_to_split, new_regions):\n",
    "    \"\"\"\n",
    "    Function to add new regions to the DataFrame by copying values of a given region.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): Input DataFrame\n",
    "    - region_to_split (str): The region whose data needs to be copied\n",
    "    - new_regions (list): List of new regions to add\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Updated DataFrame with new regions\n",
    "    \"\"\"\n",
    "    # Filter rows matching the region_to_split\n",
    "    rows_to_copy = df[df['Region'] == region_to_split]\n",
    "    \n",
    "    # Create new rows by duplicating rows_to_copy for each new region\n",
    "    for new_region in new_regions:\n",
    "        new_rows = rows_to_copy.copy()\n",
    "        new_rows['Region'] = new_region\n",
    "        df = pd.concat([df, new_rows], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load DataFrame (replace with your actual file path)\n",
    "    file_path = \"/Users/shwetat/Projects/Genesys-mod_data_repo/GENeSYS_MOD.data/Data/Parameters/Par_GeneralDiscountRate/Par_GeneralDiscountRate.csv\"  # Change this to the actual file path\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Parameters for the regions to copy and add\n",
    "    region_to_split = \"NO\"  # Region to split (source region)\n",
    "    new_regions = [\"NO1\", \"NO2\"]  # New regions to create\n",
    "    \n",
    "    # Update DataFrame\n",
    "    updated_df = add_new_regions(df, region_to_split, new_regions)\n",
    "    \n",
    "    # Save updated DataFrame\n",
    "    #updated_file_path = \"updated_\" + file_path\n",
    "    updated_df.to_csv('generaldiscountrate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_indexed(config, main_folder, output_path):\n",
    "    single_index_file = config['parameters']['changed_files1'] # list of file with parameters\n",
    "    \n",
    "    #Load each CSV file from the main folder\n",
    "    for df, file_path in process_files(main_folder):\n",
    "        #combined_new_regions = pd.DataFrame()\n",
    "        param_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "       \n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(output_path, f'{param_name}.csv')\n",
    "        for file in single_index_file:\n",
    "            if param_name == file['file_name']:\n",
    "                print(param_name)\n",
    "                method = file['method']\n",
    "                \n",
    "                regions_to_split = file['regions_to_split']\n",
    "                new_regions = file['new_regions']\n",
    "                split_ratio = file['split_ratio']\n",
    "                df = df.set_index(['Region'])\n",
    "                #print(df.head())\n",
    "                \n",
    "                \n",
    "                # Process regions to split\n",
    "                for region in regions_to_split:\n",
    "                    if region in df.index.get_level_values('Region'):\n",
    "                        print(df.head())\n",
    "                        # Filter rows for the region to split\n",
    "                    region_data = df.loc[region]\n",
    "                    print(region_data.head())\n",
    "                    # Create new DataFrame for the split regions\n",
    "                    new_region_dfs = []\n",
    "                    for new_region, ratio in split_ratio.items():\n",
    "                        #print(new_region, ratio)\n",
    "                        new_data = region_data.copy()\n",
    "\n",
    "                        new_data['Value'] *= ratio\n",
    "                        new_data['Region'] = new_region\n",
    "                        new_region_dfs.append(new_data) \n",
    "                        combined_new_regions = pd.concat(new_region_dfs, ignore_index=True)\n",
    "                        # Add the new regions back to the original DataFrame\n",
    "                        \n",
    "                        df = pd.concat([df, combined_new_regions], ignore_index=True)\n",
    "\n",
    "                        # Reapply multi-index  \n",
    "                        \n",
    "\n",
    "                        # Save the DataFrame to the constructed path\n",
    "                        df.to_csv(file_path)   \n",
    "\n",
    "                    else:\n",
    "                        print(\"do not have region in dataset\")\n",
    "                        df.to_csv(file_path)    \n",
    "\n",
    "                        combined_new_regions = pd.concat(new_region_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par_GeneralDiscountRate\n",
      "        Value  Unnamed: 2     Unit      Source  Updated at  \\\n",
      "Region                                                       \n",
      "AT       0.05         NaN  Percent  Assumption  08.09.2023   \n",
      "BE       0.05         NaN  Percent  Assumption  08.09.2023   \n",
      "BG       0.05         NaN  Percent  Assumption  08.09.2023   \n",
      "CH       0.05         NaN  Percent  Assumption  08.09.2023   \n",
      "CZ       0.05         NaN  Percent  Assumption  08.09.2023   \n",
      "\n",
      "                                      Updated by  \n",
      "Region                                            \n",
      "AT      Konstantin Löffler <kl@wip.tu-berlin.de>  \n",
      "BE      Konstantin Löffler <kl@wip.tu-berlin.de>  \n",
      "BG      Konstantin Löffler <kl@wip.tu-berlin.de>  \n",
      "CH      Konstantin Löffler <kl@wip.tu-berlin.de>  \n",
      "CZ      Konstantin Löffler <kl@wip.tu-berlin.de>  \n",
      "Value               0.05\n",
      "Unnamed: 2           NaN\n",
      "Unit             Percent\n",
      "Source        Assumption\n",
      "Updated at    08.09.2023\n",
      "Name: NO, dtype: object\n",
      "do not have region in dataset\n"
     ]
    }
   ],
   "source": [
    "single_indexed(config, base_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "havnett",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
